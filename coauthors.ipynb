{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pygraph.classes.graph import graph\n",
    "from pygraph.readwrite import dot\n",
    "from pygraph.algorithms.minmax import shortest_path\n",
    "from pygraph.algorithms.accessibility import connected_components\n",
    "from pygraph.algorithms.pagerank import pagerank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.mlab as mlab\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "import random\n",
    "import statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from network import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.core.display import Image, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def construct_graph_filtered(old_graph, node_predicate, egde_predicate):\n",
    "    new_graph = graph()\n",
    "    for node in old_graph.nodes():\n",
    "        if node_predicate(node):\n",
    "            new_graph.add_node(node)\n",
    "    for edge in old_graph.edges():\n",
    "        if not new_graph.has_edge(edge):\n",
    "            if node_predicate(edge[0]) and node_predicate(edge[1]) and egde_predicate(edge):\n",
    "                new_graph.add_edge(edge)\n",
    "    return new_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_authors_dataset(filename):\n",
    "    f = open(filename, 'r')\n",
    "    for line in f:\n",
    "        [journal, title, authors, year, abstract] = line.split(\"\\t\")\n",
    "        yield Article(title, authors.split(\",\") if authors != \"\" else [], year, journal, abstract, None, [])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_dataset_file(filename):\n",
    "    paper_title_regexp = re.compile('#\\*(.*)\\n')\n",
    "    authors_regexp = re.compile('#@(.*)\\n')\n",
    "    year_regexp = re.compile('#t(.*)\\n')\n",
    "    publication_venue_regexp = re.compile('#c(.*)\\n')\n",
    "    paper_index_regexp = re.compile('#index(.*)\\n')\n",
    "    references_ids_regexp = re.compile('#%(.*)\\n')\n",
    "    \n",
    "    f = open(filename, 'r')\n",
    "    \n",
    "    paper_title = authors = publication_venue = paper_index_id = ''\n",
    "    year = -1\n",
    "    references_ids = []\n",
    "    \n",
    "    for line in f:\n",
    "        if paper_title_regexp.search(line) is not None:\n",
    "            paper_title = paper_title_regexp.search(line).group(1)\n",
    "        elif authors_regexp.search(line) is not None:\n",
    "            authors = authors_regexp.search(line).group(1)\n",
    "        elif year_regexp.search(line) is not None:\n",
    "            year = year_regexp.search(line).group(1)\n",
    "        elif publication_venue_regexp.search(line) is not None:\n",
    "            publication_venue = publication_venue_regexp.search(line).group(1)\n",
    "        elif paper_index_regexp.search(line) is not None:\n",
    "            paper_index = paper_index_regexp.search(line).group(1)\n",
    "        elif references_ids_regexp.search(line) is not None:\n",
    "            references_ids.append(references_ids_regexp.search(line).group(1))\n",
    "        elif line == \"\\n\":\n",
    "            yield Article(paper_title, authors.split(\",\") \n",
    "                          if authors != '' else [], year, publication_venue, paper_index, None, references_ids)\n",
    "            paper_title = authors = publication_venue = paper_index_id = ''\n",
    "            year = -1\n",
    "            references_ids = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uniq authors: 2258\n"
     ]
    }
   ],
   "source": [
    "def analyse(file, loader):\n",
    "    coauthorNetwork = CoathorNetwork()\n",
    "    for article in loader(file):\n",
    "        coauthorNetwork.add_article(article)\n",
    "\n",
    "    print(\"Uniq authors:\", len([x for x in coauthorNetwork.author_to_article.keys()]))\n",
    "    return coauthorNetwork\n",
    "    \n",
    "#file = \"./data/authors/Medical Informatics.txt\"\n",
    "file = \"./data/out_test.txt\"\n",
    "coauthorNetwork = analyse(file, parse_dataset_file)\n",
    "components = connected_components(coauthorNetwork.gr)\n",
    "\n",
    "\n",
    "#!dot 'graph.dot' -Tpng -o \"graph.png\"\n",
    "#display(Image('graph.png' ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# calculate distance distribution for \n",
    "# detect small world phenomenon\n",
    "def get_distance_stat(graph, n):\n",
    "    stat = {}\n",
    "    summ = len(graph.nodes()) * n\n",
    "    for i in range(n):\n",
    "        random_author = random.choice(graph.nodes())\n",
    "        distances = shortest_path(graph, random_author)[1]\n",
    "        for x in distances.values():\n",
    "            stat[x] = stat.get(x, 0) + 1;\n",
    "    return dict( (key, value / summ) for key, value in stat.items() )\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_pagerank(graph):\n",
    "    weighted_nodes = pagerank(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def analize_components(coauthorNetwork, components, component_num):\n",
    "    PRECISION = 20 # number of authors to calc avg distance\n",
    "    component_count = max(components.values())\n",
    "\n",
    "    component_sizes = {}\n",
    "\n",
    "    for author, component in components.items():\n",
    "        component_sizes[component] = component_sizes.get(component, 0) + 1\n",
    "\n",
    "    top10_components = sorted(component_sizes.items(), key = lambda pair: -pair[1])[0:10]\n",
    "\n",
    "    top1_component = top10_components[component_num][0]\n",
    "\n",
    "    top1_subgraph = construct_graph_filtered(coauthorNetwork.gr,\n",
    "                                             lambda node: components[node] == top1_component,\n",
    "                                             lambda egde: True)\n",
    "    \n",
    "    print(len(top1_subgraph.nodes()))\n",
    "    stat = get_distance_stat(top1_subgraph, PRECISION)\n",
    "    #print(stat)\n",
    "    print(\"mean\", sum([value * key for key, value in stat.items()]))\n",
    "    plt.plot([x for x in stat.keys()], [x for x in stat.values()])\n",
    "    plt.show()\n",
    "\n",
    "analize_components(coauthorNetwork, components, 0)\n",
    "analize_components(coauthorNetwork, components, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for key, value in coauthorNetwork.author_to_article.items():\n",
    "    if len(value) > 1:\n",
    "        pass\n",
    "        #print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "g = graph()\n",
    "g.add_nodes([\"a\", \"b\"])\n",
    "g.add_node_attribute('a',(\"weight\",7))\n",
    "dot.write(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for x in coauthorNetwork.articles[0:10]:\n",
    "    print(x.__dict__)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
