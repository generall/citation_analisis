{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pygraph.classes.graph import graph\n",
    "from pygraph.readwrite import dot\n",
    "from pygraph.algorithms.minmax import shortest_path\n",
    "from pygraph.algorithms.accessibility import connected_components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.core.display import Image, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def construct_graph_filtered(old_graph, node_predicate, egde_predicate):\n",
    "    new_graph = graph()\n",
    "    for node in old_graph.nodes():\n",
    "        if node_predicate(node):\n",
    "            new_graph.add_node(node)\n",
    "    for edge in old_graph.edges():\n",
    "        if not new_graph.has_edge(edge):\n",
    "            if node_predicate(edge[0]) and node_predicate(edge[1]) and egde_predicate(edge):\n",
    "                new_graph.add_edge(edge)\n",
    "    return new_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CoathorNetwork:\n",
    "    def __init__(self):\n",
    "        self.articles = []\n",
    "        self.author_to_article = {}\n",
    "        self.gr = graph()\n",
    "        \n",
    "    def add_article(self, atricle):\n",
    "        idx = len(self.articles)\n",
    "        self.articles.append(atricle)\n",
    "        # Lookup table for each author\n",
    "        for author in atricle.authors:\n",
    "            author = author.strip()\n",
    "            articles_of_author = self.author_to_article.get(author, [])\n",
    "            articles_of_author.append(idx)\n",
    "            self.author_to_article[author] = articles_of_author\n",
    "            # Add author to graph if not exists\n",
    "            if not self.gr.has_node(author):\n",
    "                self.gr.add_node(author)\n",
    "        # Add authors to graph\n",
    "        for pair in itertools.combinations(atricle.authors, 2):\n",
    "            if not self.gr.has_edge(pair):\n",
    "                self.gr.add_edge(pair);\n",
    "    \n",
    "    def write_dot(filename):\n",
    "        f = open(filename, 'w')\n",
    "        f.write(dot.write(self.gr))\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Article:\n",
    "    def __init__(self, title, authors, year, journal, abstract, cite):\n",
    "        self.title = title\n",
    "        self.authors = authors\n",
    "        self.cite = cite\n",
    "        self.year = int(year)\n",
    "        self.journal = journal               \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_authors_dataset(filename):\n",
    "    f = open(filename, 'r')\n",
    "    for line in f:\n",
    "        [journal, title, authors, year, abstract] = line.split(\"\\t\")\n",
    "        yield Article(title, authors.split(\",\") if authors != \"\" else [], year, journal, abstract, [])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uniq authors: 7343\n"
     ]
    }
   ],
   "source": [
    "def analyse(file):\n",
    "    coauthorNetwork = CoathorNetwork()\n",
    "    for article in load_authors_dataset(file):\n",
    "        coauthorNetwork.add_article(article)\n",
    "\n",
    "    print(\"Uniq authors:\", len([x for x in coauthorNetwork.author_to_article.keys()]))\n",
    "    return coauthorNetwork\n",
    "    \n",
    "file = \"./data/authors/Medical Informatics.txt\"\n",
    "coauthorNetwork = analyse(file)\n",
    "components = connected_components(coauthorNetwork.gr)\n",
    "\n",
    "\n",
    "#!dot 'graph.dot' -Tpng -o \"graph.png\"\n",
    "#display(Image('graph.png' ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# calculate distance distribution for \n",
    "# detect small world phenomenon\n",
    "def get_distance_stat(graph, n):\n",
    "    stat = {}\n",
    "    sum = len(graph.nodes()) * n\n",
    "    for i in range(n):\n",
    "        random_author = random.choice(graph.nodes())\n",
    "        distances = shortest_path(graph, random_author)[1]\n",
    "        for x in distances.values()\n",
    "            stat[x] = stat.get(x, 0) + 1;\n",
    "    return dict(  )\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2351\n"
     ]
    }
   ],
   "source": [
    "def analize_components(coauthorNetwork, components):\n",
    "    component_count = max(components.values())\n",
    "\n",
    "    component_sizes = {}\n",
    "\n",
    "    for author, component in components.items():\n",
    "        component_sizes[component] = component_sizes.get(component, 0) + 1\n",
    "\n",
    "    top10_components = sorted(component_sizes.items(), key = lambda pair: -pair[1])[0:10]\n",
    "\n",
    "    top1_component = top10_components[0][0]\n",
    "\n",
    "    top1_subgraph = construct_graph_filtered(coauthorNetwork.gr,\n",
    "                                             lambda node: components[node] == top1_component,\n",
    "                                             lambda egde: True)\n",
    "    \n",
    "    print(len(top1_subgraph.nodes()))\n",
    "\n",
    "analize_components(coauthorNetwork, components)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for key, value in coauthorNetwork.author_to_article.items():\n",
    "    if len(value) > 1:\n",
    "        pass\n",
    "        #print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'dict' and 'dict'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-114-94a4c1d18078>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;33m{\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m}\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'dict' and 'dict'"
     ]
    }
   ],
   "source": [
    "{1:2} + {1:3}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
